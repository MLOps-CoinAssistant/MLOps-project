{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from sqlalchemy import create_engine, select, text\n",
    "from sqlalchemy.orm import Session\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#from dags.module.info.connections import Connections\n",
    "\n",
    "#import sys\n",
    "#import os\n",
    "\n",
    "# module_path = '/home/ubuntu/MLOps-project'\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL 연결 정보를 환경 변수에서 가져옵니다.\n",
    "#postgres_hook = PostgresHook(postgres_conn_id=Connections.POSTGRES_DEFAULT.value)\n",
    "# 데이터베이스 연결 엔진을 생성합니다.\n",
    "engine = create_engine('postgresql://postgres:ls_mle_course@34.22.85.119:5432')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션을 생성하여 데이터베이스 연결\n",
    "with Session(bind=engine) as session:\n",
    "    query = text(\"SELECT * FROM btc_ohlc\")\n",
    "    \n",
    "    # 쿼리 실행 및 결과를 pandas 데이터프레임으로 변환\n",
    "    result = session.execute(query)\n",
    "    df = pd.DataFrame(result.all(), columns=result.keys())\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()     # non-null한 데이터. time 제외하고 int타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()  # open,high,low,close 중에 0인 값이 있거나, 이상치로 느껴지는 부분은 없는 것 같다. volume 분포 확인필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume = 0 인 데이터 호출\n",
    "df[df['volume'] == 0]  # 3개의 데이터 발견."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['volume'] > 2000].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 컬럼이 오름차순으로 정렬되어 있는지 확인 (오름차순 : True, 아니면 : False)\n",
    "is_sorted = df['time'].is_monotonic_increasing\n",
    "is_sorted # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['close'], label='Close Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Bitcoin Close Price Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['volume'], label='Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.title('Bitcoin Volume Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 히스토그램을 통한 데이터 분포 시각화(volume)  -> skewed \n",
    "df.hist('volume', bins=100, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  가격 변동성 분석\n",
    "df['price_diff'] = df['high'] - df['low']\n",
    "df['log_return'] = np.log(df['close'] / df['close'].shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일일 변동폭 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['price_diff'], label='Daily Price Range (High - Low)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price Difference')\n",
    "plt.title('Daily Price Range')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일일 로그 수익률 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['log_return'], label='Daily Log Return')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Return')\n",
    "plt.title('Daily Log Return')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['log_return'].isnull()] # 로그 수익률을 만들 때 shift(1) 을 하기 때문에 첫 행에서 nan값 발생."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  거래량과 가격의 관계 분석\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df['volume'], y=df['close'])\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Volume vs. Close Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 계산\n",
    "correlation = df[['volume', 'close', 'price_diff', 'log_return']].corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation)\n",
    "\n",
    "# 상관관계 히트맵\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 박스플롯을 통한 이상치 확인 (volume)\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=df[['volume']])\n",
    "plt.title('Boxplot of volume')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "eda 결과\n",
    "전체적으로 결측치는 존재하지 않았고, 시간순으로 잘 정렬되어있다.\n",
    "거래량과 가격의 상관관계는 크지 않았다. \n",
    "volume 컬럼에서 0인 데이터가 3개 발견되었고 이 부분은 삭제하기 보다는 누락되는 시간이 없도록 하기 위해 선형보간법으로 채워줄 예정\n",
    "volume 컬럼에서 이상치라고 할 수 있는 큰 값들이 존재하긴 하지만 많지 않고, 거래량은 비트코인 특성상 큰 값도 유의미하다고 생각해서\n",
    "삭제까진 하지 않고,  유지하고 스케일링만 할 예정\n",
    "가격 변동성을 확인할 수 있는 컬럼을 추가해서 확인해 보았다.\n",
    "일일 가격 변동폭 : df['price_diff'] = df['high'] - df['low']\n",
    "일일 로그수익률 : df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "여기서 로그수익률 컬럼을 만드는 과정에서 첫번째 인덱스에 nan값이 들어감.\n",
    "scatterplot 확인결과 대부분의 거래가 거래량이 낮은 거래량(1000이하)에서 이루어지고 있음.\n",
    "3000 이상을 이상치로 판단하면 될것 같다.\n",
    "\n",
    "\n",
    "전처리 단계에서 할 일\n",
    "\n",
    "1. volume = 0 인 컬럼 선형보간법 적용하기\n",
    "2. volume > 3000 이상인 값은 3000으로 일괄 적용한 후 로그스케일링 적용하기\n",
    "3. 'price_diff', 'log_return' 컬럼 추가하기\n",
    "4. time 컬럼은 year, month, day, hour, 등의 피쳐로 나눠서 시간의 주기성을 반영하기 위해 \n",
    "시간을 24시간을 주기로 사인과 코사인 변환하여 시간대 정보를 캡쳐\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 박스플롯을 통한 이상치 확인 (volume)\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=df[['volume']])\n",
    "plt.title('Boxplot of volume')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import Session\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# PostgreSQL 연결 정보를 환경 변수에서 가져온다.\n",
    "# 데이터베이스 연결 엔진을 생성한다.\n",
    "engine = create_engine('postgresql://postgres:ls_mle_course@34.22.85.119:5432')\n",
    "\n",
    "# 세션을 생성하여 데이터베이스 연결\n",
    "with Session(bind=engine) as session:\n",
    "    query = text(\"SELECT * FROM btc_ohlc\")\n",
    "\n",
    "    # 쿼리 실행 및 결과를 pandas 데이터프레임으로 변환\n",
    "    result = session.execute(query)\n",
    "    df = pd.DataFrame(result.all(), columns=result.keys())\n",
    "    session.commit()\n",
    "\n",
    "# 데이터 확인\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(df.info())     \n",
    "print(df.isnull().sum())\n",
    "print(df.describe())\n",
    "\n",
    "# volume = 0 인 데이터 호출\n",
    "print(df[df['volume'] == 0])  \n",
    "\n",
    "# time 컬럼이 오름차순으로 정렬되어 있는지 확인\n",
    "is_sorted = df['time'].is_monotonic_increasing\n",
    "print(is_sorted) \n",
    "\n",
    "# 시계열 데이터 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['close'], label='Close Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Bitcoin Close Price Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 시계열 데이터 시각화 (Volume)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['volume'], label='Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.title('Bitcoin Volume Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 히스토그램을 통한 데이터 분포 시각화(volume)\n",
    "df.hist('volume', bins=100, figsize=(10, 10))\n",
    "plt.show()\n",
    "\n",
    "# 가격 변동성 분석\n",
    "df['price_diff'] = df['high'] - df['low']\n",
    "df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "# 일일 변동폭 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['price_diff'], label='Daily Price Range (High - Low)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price Difference')\n",
    "plt.title('Daily Price Range')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 일일 로그 수익률 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['log_return'], label='Daily Log Return')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Return')\n",
    "plt.title('Daily Log Return')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 거래량과 가격의 관계 분석\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df['volume'], y=df['close'])\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Volume vs. Close Price')\n",
    "plt.show()\n",
    "\n",
    "# 상관관계 계산\n",
    "correlation = df[['volume', 'close', 'price_diff', 'log_return']].corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation)\n",
    "\n",
    "# 상관관계 히트맵\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 박스플롯을 통한 이상치 확인 (volume)\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=df[['volume']])\n",
    "plt.title('Boxplot of volume')\n",
    "plt.show()\n",
    "\n",
    "# 전처리 단계\n",
    "\n",
    "# 1. volume = 0 인 컬럼 선형보간법 적용하기\n",
    "df['volume'] = df['volume'].replace(0, np.nan)\n",
    "df['volume'] = df['volume'].interpolate()\n",
    "\n",
    "# 2. volume > 3000 이상인 값은 3000으로 일괄 적용한 후 로그스케일링 적용하기\n",
    "df['volume'] = df['volume'].apply(lambda x: 3000 if x > 3000 else x)\n",
    "df['log_volume'] = np.log(df['volume'] + 1)  # 로그 변환 시 0이 되는 것을 방지하기 위해 +1을 더함\n",
    "\n",
    "# 3. 'price_diff', 'log_return' 컬럼 추가하기\n",
    "df['price_diff'] = df['high'] - df['low']\n",
    "df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "# 4. time 컬럼은 year, month, day, hour, 등의 피쳐로 나눠서 시간의 주기성을 반영하기 위해\n",
    "df['year'] = df['time'].dt.year\n",
    "df['month'] = df['time'].dt.month\n",
    "df['day'] = df['time'].dt.day\n",
    "df['hour'] = df['time'].dt.hour\n",
    "\n",
    "# 시간 정보를 캡쳐하기 위해 사인과 코사인 변환\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "추세 분석 (Trend Analysis)\n",
    "•\t시계열 데이터의 장기적인 추세를 확인\n",
    "•\t이동 평균 (Moving Average)을 사용하여 추세를 부드럽게 함\n",
    "'''\n",
    "# 이동 평균 계산\n",
    "df['moving_average_30'] = df['close'].rolling(window=30).mean()\n",
    "\n",
    "# 시계열 데이터 시각화 (Moving Average)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['close'], label='Close Price')\n",
    "plt.plot(df['time'], df['moving_average_30'], label='30-day Moving Average')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Bitcoin Close Price with Moving Average')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "그래프에서 원본 종가 데이터는 빠르고 큰 변동을 보여주며, 이는 비트코인의 높은 변동성을 반영한다.\n",
    "\n",
    "30일 이동 평균의 이유\n",
    "1.\t단기 및 중기 추세 파악:\n",
    "    •\t단기 및 중기 추세를 파악하는 데 유용\n",
    "    •\t시장의 단기적인 변화를 이해하는 데 도움을 줌\n",
    "2.\t일반적인 관행:\n",
    "    •\t30일 이동 평균은 주식, 암호화폐 등 다양한 자산에서 많이 사용되는 일반적인 기준\n",
    "    •\t많은 투자자와 분석가들이 사용하는 표준\n",
    "\n",
    "다른 이동 평균 기간\n",
    "1.\t7일 이동 평균:\n",
    "\t•\t단기 추세 파악: 일주일 간의 단기적인 가격 변동을 분석할 때 유용\n",
    "\t•\t변동성 확인: 단기적인 변동성을 더 민감하게 반영\n",
    "\n",
    "단기(7일, 14일), 중기(30일, 50일), 장기(100일, 200일) 이동 평균을 함께 사용하면 데이터의 여러 측면을 분석할 수 있다.\n",
    "각 기간은 다른 종류의 추세를 강조하며, 이를 통해 더 균형 잡힌 분석을 할 수 있다. \n",
    "시장의 변동성이 높을 때는 단기 이동 평균이 유용하다. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동 평균 계산\n",
    "df['moving_average_7'] = df['close'].rolling(window=7).mean()\n",
    "df['moving_average_30'] = df['close'].rolling(window=30).mean()\n",
    "df['moving_average_50'] = df['close'].rolling(window=50).mean()\n",
    "df['moving_average_100'] = df['close'].rolling(window=100).mean()\n",
    "df['moving_average_200'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "# 시계열 데이터 시각화 (다양한 이동 평균)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['close'], label='Close Price')\n",
    "plt.plot(df['time'], df['moving_average_7'], label='7-day Moving Average', color='green')\n",
    "plt.plot(df['time'], df['moving_average_30'], label='30-day Moving Average', color='orange')\n",
    "plt.plot(df['time'], df['moving_average_50'], label='50-day Moving Average', color='red')\n",
    "plt.plot(df['time'], df['moving_average_100'], label='100-day Moving Average', color='purple')\n",
    "plt.plot(df['time'], df['moving_average_200'], label='200-day Moving Average', color='brown')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.title('Bitcoin Close Price with Various Moving Averages')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 이동 평균 계산\n",
    "df['moving_average_7'] = df['close'].rolling(window=7).mean()\n",
    "df['moving_average_30'] = df['close'].rolling(window=30).mean()\n",
    "df['moving_average_50'] = df['close'].rolling(window=50).mean()\n",
    "df['moving_average_100'] = df['close'].rolling(window=100).mean()\n",
    "df['moving_average_200'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "# 결측치 제거 (이동 평균 계산으로 인해 생긴 NaN 값)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 피처와 타겟 변수 정의\n",
    "features = ['open', 'high', 'low', 'volume', 'moving_average_7', 'moving_average_30', 'moving_average_50', 'moving_average_100', 'moving_average_200']\n",
    "target = 'close'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# 데이터 분할 (훈련 세트와 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 훈련\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# 피처 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "indices = np.argsort(feature_importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), feature_importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "계절성 분석 (Seasonality Analysis)\n",
    "•\t데이터의 계절적 패턴을 분석\n",
    "•\t특정 시간, 월, 계절에 따라 변동하는 패턴을 찾는다.\n",
    "'''\n",
    "\n",
    "# 월별 평균 가격 계산\n",
    "df['month'] = df['time'].dt.month\n",
    "monthly_avg = df.groupby('month')['close'].mean()\n",
    "\n",
    "# 월별 평균 가격 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_avg.plot(kind='bar')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Close Price')\n",
    "plt.title('Monthly Average Close Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "잔차 분석 (Residual Analysis)\n",
    "•\t추세와 계절성을 제거한 후 남은 잔차를 분석\n",
    "•\tARIMA 모델을 사용하여 예측하고 잔차를 분석할 수 있다.\n",
    "'''\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# 시계열 분해\n",
    "decomposition = seasonal_decompose(df['close'], model='additive', period=365)\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(411)\n",
    "plt.plot(df['close'], label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend') # 추세\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal, label='Seasonality') # 계절성\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals') # 잔차\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# 추세는 장기적인 방향성을 보여주며, 계절성은 주기적인 변동을 나타낸다. 잔차는 나머지 부분을 포함한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 시계열 분해\n",
    "decomposition = seasonal_decompose(df['close'], model='additive', period=365)\n",
    "df['trend'] = decomposition.trend\n",
    "df['seasonal'] = decomposition.seasonal\n",
    "df['residual'] = decomposition.resid\n",
    "\n",
    "# 결측치 제거 (시계열 분해로 인해 생긴 NaN 값)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 이동 평균 계산\n",
    "df['moving_average_7'] = df['close'].rolling(window=7).mean()\n",
    "df['moving_average_30'] = df['close'].rolling(window=30).mean()\n",
    "df['moving_average_50'] = df['close'].rolling(window=50).mean()\n",
    "df['moving_average_100'] = df['close'].rolling(window=100).mean()\n",
    "df['moving_average_200'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "# 결측치 제거 (이동 평균 계산으로 인해 생긴 NaN 값)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 피처와 타겟 변수 정의\n",
    "features = ['open', 'high', 'low', 'volume', 'moving_average_7', 'moving_average_30', 'moving_average_50', \n",
    "            'moving_average_100', 'moving_average_200', 'trend', 'seasonal', 'residual']\n",
    "target = 'close'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# 데이터 분할 (훈련 세트와 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 훈련\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# 피처 중요도 시각화\n",
    "feature_importances = model.feature_importances_\n",
    "indices = np.argsort(feature_importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), feature_importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "변동성 분석 (Volatility Analysis)\n",
    "•\t데이터의 변동성을 분석하여 안정성을 평가\n",
    "•\t일일 수익률의 표준 편차를 계산\n",
    "'''\n",
    "\n",
    "# 일일 수익률의 표준 편차 계산\n",
    "volatility = df['log_return'].std()\n",
    "\n",
    "print(\"Daily Log Return Volatility:\", volatility)\n",
    "\n",
    "# 변동성 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['time'], df['log_return'].rolling(window=30).std(), label='30-day Rolling Volatility')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.title('Bitcoin Rolling Volatility')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "•\t로그 수익률의 표준 편차를 계산하여 일일 변동성을 측정함\n",
    "•\t변동성은 가격 변동의 크기를 나타내며, 높은 변동성은 리스크가 높음을 의미한다.\n",
    "•\t30일 이동 표준 편차를 사용하여 변동성의 변화를 시각화했다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 로그 리턴 계산\n",
    "df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "# 변동성 계산 (30일 이동 표준 편차)\n",
    "df['volatility_30'] = df['log_return'].rolling(window=30).std()\n",
    "\n",
    "# 결측치 제거 (로그 리턴과 변동성 계산으로 인해 생긴 NaN 값)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 이동 평균 계산\n",
    "df['moving_average_7'] = df['close'].rolling(window=7).mean()\n",
    "df['moving_average_30'] = df['close'].rolling(window=30).mean()\n",
    "df['moving_average_50'] = df['close'].rolling(window=50).mean()\n",
    "df['moving_average_100'] = df['close'].rolling(window=100).mean()\n",
    "df['moving_average_200'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "# 결측치 제거 (이동 평균 계산으로 인해 생긴 NaN 값)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 피처와 타겟 변수 정의\n",
    "features = ['open', 'high', 'low', 'volume', 'moving_average_7', 'moving_average_30', 'moving_average_50', \n",
    "            'moving_average_100', 'moving_average_200', 'log_return', 'volatility_30']\n",
    "target = 'close'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# 데이터 분할 (훈련 세트와 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 훈련\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# 피처 중요도 시각화\n",
    "feature_importances = model.feature_importances_\n",
    "indices = np.argsort(feature_importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), feature_importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "이상치 탐지 (Outlier Detection)\n",
    "•\t비정상적인 데이터 포인트를 탐지하고 제거\n",
    "•\tIQR (Interquartile Range) 방법을 사용\n",
    "'''\n",
    "\n",
    "# IQR을 사용한 이상치 탐지\n",
    "Q1 = df['close'].quantile(0.25)\n",
    "Q3 = df['close'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df[(df['close'] < (Q1 - 1.5 * IQR)) | (df['close'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "print(\"Outliers detected:\")\n",
    "print(outliers)\n",
    "'''\n",
    "이상치가 발견되지 않았다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "자기상관 분석 (Autocorrelation Analysis)\n",
    "•\t데이터의 자기상관성을 분석하여 패턴을 찾는다.\n",
    "•\tACF (Autocorrelation Function)와 PACF (Partial Autocorrelation Function)를 사용\n",
    "'''\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# ACF와 PACF 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_acf(df['log_return'].dropna(), lags=50)\n",
    "plt.title('Autocorrelation Function')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_pacf(df['log_return'].dropna(), lags=50)\n",
    "plt.title('Partial Autocorrelation Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from sqlalchemy import create_engine, select, text\n",
    "from sqlalchemy.orm import Session\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "engine = create_engine('postgresql://postgres:ls_mle_course@34.22.85.119:5432')\n",
    "\n",
    "# 세션을 생성하여 데이터베이스 연결\n",
    "with Session(bind=engine) as session:\n",
    "    query = text(\"SELECT * FROM btc_ohlc\")\n",
    "    \n",
    "    # 쿼리 실행 및 결과를 pandas 데이터프레임으로 변환\n",
    "    result = session.execute(query)\n",
    "    df = pd.DataFrame(result.all(), columns=result.keys())\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 리턴 계산\n",
    "df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "# 변동성 계산 (30일 이동 표준 편차)\n",
    "df['volatility_30'] = df['log_return'].rolling(window=30).std()\n",
    "\n",
    "# 이동 평균 계산\n",
    "df['moving_average_7'] = df['close'].rolling(window=7).mean()\n",
    "df['moving_average_30'] = df['close'].rolling(window=30).mean()\n",
    "df['moving_average_50'] = df['close'].rolling(window=50).mean()\n",
    "df['moving_average_100'] = df['close'].rolling(window=100).mean()\n",
    "df['moving_average_200'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "# 결측치 제거 (이동 평균 계산으로 인해 생긴 NaN 값)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 피처와 타겟 변수 정의\n",
    "features = ['open', 'high', 'low', 'volume', 'moving_average_7', 'moving_average_30', 'moving_average_50', \n",
    "            'moving_average_100', 'moving_average_200', 'log_return', 'volatility_30']\n",
    "target = 'close'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# 데이터 분할 (훈련 세트와 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 훈련\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# 피처 중요도 시각화\n",
    "feature_importances = model.feature_importances_\n",
    "indices = np.argsort(feature_importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), feature_importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
